# -*- coding: utf-8 -*-
"""
Ù†Ø¸Ø§Ù… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø­ÙƒØ§Ù… Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠØ© ÙˆÙƒØ´Ù Ø§Ù„Ø´Ø°ÙˆØ° - Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
ØªØ¹Ù…Ù„ Ø¹Ù„Ù‰ Ù…Ù„Ù database.csv Ù…Ø¹ ØªÙ‚Ø³ÙŠÙ… 80% ØªØ¯Ø±ÙŠØ¨ - 20% Ø§Ø®ØªØ¨Ø§Ø±
Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©: streamlit, pandas, numpy, plotly, scikit-learn, xgboost, matplotlib
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import time
import warnings
import os
from io import StringIO
import matplotlib.pyplot as plt
warnings.filterwarnings('ignore')

# ==================== Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ ====================
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import (accuracy_score, precision_score, recall_score, 
                             f1_score, confusion_matrix, classification_report,
                             roc_curve, auc)

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ XGBoost
import xgboost as xgb
from xgboost import XGBClassifier

# ==================== Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ====================
st.set_page_config(
    page_title="Ø¹Ø¯Ø§Ù„Ø©âš–ï¸ - Ù†Ø¸Ø§Ù… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø­ÙƒØ§Ù… Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠØ©",
    page_icon="âš–ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==================== CSS Ù…Ø®ØµØµ ====================
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Cairo:wght@300;400;600;700;900&display=swap');
    * { font-family: 'Cairo', sans-serif; }
    
    .header {
        background: linear-gradient(135deg, #0a3147, #1a4b6d);
        color: white;
        padding: 2rem;
        border-radius: 0 0 30px 30px;
        text-align: center;
        margin-bottom: 2rem;
        box-shadow: 0 10px 30px rgba(0,20,40,0.3);
    }
    .header h1 { 
        font-size: 3rem; 
        font-weight: 900; 
        margin-bottom: 0.5rem;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.2);
    }
    .header p { 
        font-size: 1.2rem; 
        opacity: 0.9;
        max-width: 800px;
        margin: 0 auto;
    }
    
    .card {
        background: white;
        border-radius: 20px;
        padding: 1.8rem;
        box-shadow: 0 8px 25px rgba(0,0,0,0.05);
        margin-bottom: 1.5rem;
        border: 1px solid #eaeef2;
        transition: all 0.3s ease;
    }
    .card:hover {
        box-shadow: 0 15px 35px rgba(26,75,109,0.1);
        transform: translateY(-3px);
    }
    .card-title {
        font-size: 1.4rem;
        font-weight: 700;
        color: #1a4b6d;
        margin-bottom: 1.2rem;
        border-bottom: 2px solid #eaeef2;
        padding-bottom: 0.7rem;
    }
    
    .metric-container {
        display: flex;
        flex-wrap: wrap;
        gap: 1rem;
        margin: 1.5rem 0;
    }
    .metric-card {
        background: linear-gradient(135deg, #f8fbff, #ffffff);
        border-radius: 18px;
        padding: 1.2rem;
        box-shadow: 0 5px 15px rgba(0,0,0,0.03);
        text-align: center;
        flex: 1 1 180px;
        border: 1px solid #dde5ed;
        transition: all 0.3s;
    }
    .metric-card:hover {
        border-color: #1a4b6d;
        box-shadow: 0 8px 20px rgba(26,75,109,0.15);
    }
    .metric-value {
        font-size: 2.2rem;
        font-weight: 900;
        color: #0a3147;
        line-height: 1.2;
    }
    .metric-label {
        color: #5f6b7a;
        font-size: 0.9rem;
        font-weight: 600;
        text-transform: uppercase;
        letter-spacing: 0.5px;
    }
    
    .badge-normal {
        background: linear-gradient(135deg, #d4edda, #c3e6cb);
        color: #155724;
        padding: 0.5rem 1rem;
        border-radius: 50px;
        font-weight: 700;
        display: inline-block;
        border-right: 4px solid #28a745;
    }
    .badge-anomaly {
        background: linear-gradient(135deg, #f8d7da, #f5c6cb);
        color: #721c24;
        padding: 0.5rem 1rem;
        border-radius: 50px;
        font-weight: 700;
        display: inline-block;
        border-right: 4px solid #dc3545;
    }
    .badge-warning {
        background: linear-gradient(135deg, #fff3cd, #ffeeba);
        color: #856404;
        padding: 0.5rem 1rem;
        border-radius: 50px;
        font-weight: 700;
        display: inline-block;
        border-right: 4px solid #ffc107;
    }
    
    .alert-success {
        background: linear-gradient(135deg, #d4edda, #c3e6cb);
        border-right: 8px solid #28a745;
        padding: 1.2rem;
        border-radius: 15px;
        margin: 1.2rem 0;
        color: #155724;
        font-weight: 600;
        box-shadow: 0 5px 15px rgba(40,167,69,0.1);
    }
    .alert-danger {
        background: linear-gradient(135deg, #f8d7da, #f5c6cb);
        border-right: 8px solid #dc3545;
        padding: 1.2rem;
        border-radius: 15px;
        margin: 1.2rem 0;
        color: #721c24;
        font-weight: 600;
        box-shadow: 0 5px 15px rgba(220,53,69,0.1);
    }
    .alert-warning {
        background: linear-gradient(135deg, #fff3cd, #ffeeba);
        border-right: 8px solid #ffc107;
        padding: 1.2rem;
        border-radius: 15px;
        margin: 1.2rem 0;
        color: #856404;
        font-weight: 600;
        box-shadow: 0 5px 15px rgba(255,193,7,0.1);
    }
    .alert-info {
        background: linear-gradient(135deg, #d1ecf1, #bee5eb);
        border-right: 8px solid #17a2b8;
        padding: 1.2rem;
        border-radius: 15px;
        margin: 1.2rem 0;
        color: #0c5460;
        font-weight: 600;
        box-shadow: 0 5px 15px rgba(23,162,184,0.1);
    }
    
    .feature-bar {
        height: 8px;
        background: linear-gradient(90deg, #1a4b6d, #4a90e2);
        border-radius: 4px;
        margin: 0.5rem 0;
    }
    
    .stButton > button {
        background: linear-gradient(135deg, #1a4b6d, #2c5f8a);
        color: white;
        font-weight: 700;
        border: none;
        border-radius: 12px;
        padding: 0.8rem 2rem;
        width: 100%;
        font-size: 1.1rem;
        transition: all 0.3s ease;
        box-shadow: 0 5px 15px rgba(26,75,109,0.3);
    }
    .stButton > button:hover {
        background: linear-gradient(135deg, #2c5f8a, #1a4b6d);
        transform: translateY(-3px);
        box-shadow: 0 8px 25px rgba(26,75,109,0.4);
    }
    
    .footer {
        background: linear-gradient(135deg, #0a3147, #1a4b6d);
        color: white;
        padding: 2rem;
        border-radius: 30px 30px 0 0;
        margin-top: 4rem;
        text-align: center;
        box-shadow: 0 -10px 30px rgba(0,0,0,0.1);
    }
    
    .stTabs [data-baseweb="tab-list"] {
        gap: 1rem;
    }
    .stTabs [data-baseweb="tab"] {
        background: white;
        border-radius: 12px 12px 0 0;
        padding: 0.8rem 1.8rem;
        font-weight: 700;
        color: #5f6b7a;
        border: 1px solid #eaeef2;
        border-bottom: none;
    }
    .stTabs [aria-selected="true"] {
        background: linear-gradient(135deg, #1a4b6d, #2c5f8a);
        color: white !important;
    }
    
    hr {
        border: none;
        height: 2px;
        background: linear-gradient(90deg, transparent, #1a4b6d, transparent);
        margin: 2rem 0;
    }
</style>
""", unsafe_allow_html=True)

# ==================== ØªÙ‡ÙŠØ¦Ø© Ø­Ø§Ù„Ø© Ø§Ù„Ø¬Ù„Ø³Ø© ====================
if 'data_loaded' not in st.session_state:
    st.session_state.data_loaded = False
if 'model_trained' not in st.session_state:
    st.session_state.model_trained = False
if 'df' not in st.session_state:
    st.session_state.df = None
if 'model_pack' not in st.session_state:
    st.session_state.model_pack = None

# ==================== ØªØ­Ù…ÙŠÙ„ ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù„Ù database.csv ====================
def load_and_process_database(file):
    """
    ØªØ­Ù…ÙŠÙ„ ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù„Ù database.csv Ø§Ù„ÙØ¹Ù„ÙŠ
    """
    try:
        # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù Ù…Ø¹ ØªØ­Ø¯ÙŠØ¯ Ø£Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù†ØµÙŠØ© Ù‚Ø¯ ØªÙƒÙˆÙ† ÙƒØ¨ÙŠØ±Ø©
        df = pd.read_csv(file, low_memory=False)
        
        # Ø¹Ø±Ø¶ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        st.info(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(df):,} Ø³Ø¬Ù„ Ùˆ {len(df.columns)} Ø¹Ù…ÙˆØ¯")
        
        # Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ù‡Ù…Ø© Ù„Ù„ØªØ­Ù„ÙŠÙ„ - ØªÙ… Ø§Ø®ØªÙŠØ§Ø±Ù‡Ø§ Ø¨Ø¹Ù†Ø§ÙŠØ© Ù…Ù† Ø¨Ù†ÙŠØ© Ø§Ù„Ù…Ù„Ù
        relevant_columns = {
            'case_id': 'Ø±Ù‚Ù…_Ø§Ù„Ù‚Ø¶ÙŠØ©',
            'decision_type': 'Ù†ÙˆØ¹_Ø§Ù„Ù‚Ø±Ø§Ø±',
            'case_disposition': 'Ù†ØªÙŠØ¬Ø©_Ø§Ù„Ù‚Ø¶ÙŠØ©',
            'issue_area': 'Ù…Ø¬Ø§Ù„_Ø§Ù„Ù‚Ø¶ÙŠØ©',
            'party_winning': 'Ø§Ù„Ø·Ø±Ù_Ø§Ù„ÙØ§Ø¦Ø²',
            'precedent_alteration': 'ØªØºÙŠÙŠØ±_Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©',
            'chief_justice': 'Ø±Ø¦ÙŠØ³_Ø§Ù„Ù…Ø­ÙƒÙ…Ø©',
            'split_vote': 'ØªØµÙˆÙŠØª_Ù…Ù†Ù‚Ø³Ù…',
            'decision_direction': 'Ø§ØªØ¬Ø§Ù‡_Ø§Ù„Ù‚Ø±Ø§Ø±'
        }
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙØ¹Ù„ÙŠØ§Ù‹ ÙÙŠ Ø§Ù„Ù…Ù„Ù
        available_columns = {}
        for eng_col, ar_col in relevant_columns.items():
            if eng_col in df.columns:
                available_columns[eng_col] = ar_col
        
        if not available_columns:
            st.error("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© ÙÙŠ Ø§Ù„Ù…Ù„Ù")
            return None
        
        # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ØªØ§Ø­Ø© ÙÙ‚Ø·
        df_selected = df[list(available_columns.keys())].copy()
        
        # Ø¥Ø¹Ø§Ø¯Ø© ØªØ³Ù…ÙŠØ© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø¥Ù„Ù‰ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
        df_selected.rename(columns=available_columns, inplace=True)
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©
        initial_rows = len(df_selected)
        df_selected.dropna(inplace=True)
        dropped_rows = initial_rows - len(df_selected)
        
        if dropped_rows > 0:
            st.warning(f"âš ï¸ ØªÙ… Ø­Ø°Ù {dropped_rows:,} ØµÙØ§Ù‹ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù‚ÙŠÙ… ÙØ§Ø±ØºØ©")
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ÙØ¦ÙˆÙŠØ© Ø¥Ù„Ù‰ Ù‚ÙŠÙ… Ø±Ù‚Ù…ÙŠØ©
        categorical_cols = df_selected.select_dtypes(include=['object']).columns.tolist()
        
        # Ø¥Ø¶Ø§ÙØ© Ø¹Ù…ÙˆØ¯ "Ù…Ø­Ù„ÙŠ/Ø¯ÙˆÙ„ÙŠ" ØªØ¬Ø±ÙŠØ¨ÙŠ (Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹)
        if 'Ù…Ø­Ù„ÙŠ' not in df_selected.columns:
            df_selected['Ù…Ø­Ù„ÙŠ'] = np.random.choice([0, 1], size=len(df_selected), p=[0.7, 0.3])
        
        # ØªØ­ÙˆÙŠÙ„ 'ØªØµÙˆÙŠØª_Ù…Ù†Ù‚Ø³Ù…' Ø¥Ù„Ù‰ Ù‚ÙŠÙ… Ø±Ù‚Ù…ÙŠØ© Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹
        if 'ØªØµÙˆÙŠØª_Ù…Ù†Ù‚Ø³Ù…' in df_selected.columns:
            df_selected['ØªØµÙˆÙŠØª_Ù…Ù†Ù‚Ø³Ù…'] = pd.to_numeric(df_selected['ØªØµÙˆÙŠØª_Ù…Ù†Ù‚Ø³Ù…'], errors='coerce').fillna(0)
        
        # Ø¥Ø¶Ø§ÙØ© Ø¹Ù…ÙˆØ¯ Ù‚ÙˆØ© Ø§Ù„Ø£Ø¯Ù„Ø© ØªØ¬Ø±ÙŠØ¨ÙŠ
        df_selected['Ù‚ÙˆØ©_Ø§Ù„Ø£Ø¯Ù„Ø©'] = np.random.randint(1, 6, size=len(df_selected))
        
        return df_selected
        
    except Exception as e:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù: {str(e)}")
        return None

# ==================== ØªÙˆÙ„ÙŠØ¯ Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ© (Ø§Ø­ØªÙŠØ§Ø·ÙŠ) ====================
def generate_sample_data(n_samples=2000):
    """
    ØªÙˆÙ„ÙŠØ¯ Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ© Ù„Ù„Ù…Ø­Ø§ÙƒØ§Ø© ÙÙŠ Ø­Ø§Ù„ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù
    """
    np.random.seed(42)
    
    data = {
        'Ø±Ù‚Ù…_Ø§Ù„Ù‚Ø¶ÙŠØ©': range(1, n_samples + 1),
        'Ù†ÙˆØ¹_Ø§Ù„Ù‚Ø±Ø§Ø±': np.random.choice([1, 2, 3, 4, 5, 6, 7], n_samples),
        'Ù†ØªÙŠØ¬Ø©_Ø§Ù„Ù‚Ø¶ÙŠØ©': np.random.choice([1, 2, 3, 4, 5, 6, 7, 8, 9], n_samples),
        'Ù…Ø¬Ø§Ù„_Ø§Ù„Ù‚Ø¶ÙŠØ©': np.random.choice(range(1, 14), n_samples),
        'Ø§Ù„Ø·Ø±Ù_Ø§Ù„ÙØ§Ø¦Ø²': np.random.choice([1, 2, 3], n_samples, p=[0.4, 0.4, 0.2]),
        'ØªØºÙŠÙŠØ±_Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©': np.random.choice([0, 1], n_samples, p=[0.8, 0.2]),
        'Ø±Ø¦ÙŠØ³_Ø§Ù„Ù…Ø­ÙƒÙ…Ø©': np.random.choice(['ÙˆØ§Ø±Ù†', 'Ø¨Ø±Ø¬Ø±', 'ÙÙŠÙ†Ø³ÙˆÙ†', 'Ø±ÙŠÙ†ÙƒÙˆÙŠØ³Øª'], n_samples),
        'ØªØµÙˆÙŠØª_Ù…Ù†Ù‚Ø³Ù…': np.random.choice([0, 1], n_samples, p=[0.6, 0.4]),
        'Ø§ØªØ¬Ø§Ù‡_Ø§Ù„Ù‚Ø±Ø§Ø±': np.random.choice([1, 2, 3], n_samples),
        'Ù…Ø­Ù„ÙŠ': np.random.choice([0, 1], n_samples, p=[0.7, 0.3]),
        'Ù‚ÙˆØ©_Ø§Ù„Ø£Ø¯Ù„Ø©': np.random.randint(1, 6, n_samples)
    }
    
    return pd.DataFrame(data)

# ==================== Ø¯Ø§Ù„Ø© MCAS ====================
def mcas_score(y_true, y_pred, lambda1=1, lambda2=1):
    """
    Ø­Ø³Ø§Ø¨ Ù…Ù‚ÙŠØ§Ø³ MCAS (Ù…Ø­Ø§ÙƒØ§Ø©)
    """
    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()
    
    css_plus = tp / (tp + fp + fn) if (tp + fp + fn) > 0 else 0
    css_minus = tn / (tn + fp + fn) if (tn + fp + fn) > 0 else 0
    
    cfs = 0.5 * (
        (fp / (tp + tn + fp) if (tp + tn + fp) > 0 else 0) +
        (fn / (tp + tn + fn) if (tp + tn + fn) > 0 else 0)
    )
    
    mcas = (lambda1 * (css_plus - cfs) + lambda2 * (css_minus - cfs)) / (lambda1 + lambda2)
    return max(0, min(1, mcas))

# ==================== ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹ XGBoost ====================
def train_model_with_xgboost(df, test_size=0.2, random_state=42):
    """
    ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ XGBoost Ù…Ø¹ ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª 80% ØªØ¯Ø±ÙŠØ¨ - 20% Ø§Ø®ØªØ¨Ø§Ø±
    
    Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª:
    - XGBoost Ø£Ø³Ø±Ø¹ ÙˆØ£Ø¯Ù‚ Ù…Ù† Random Forest
    - ÙŠØ¯Ø¹Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ø§Ù„Ù…ØªÙˆØ§Ø²Ù†Ø©
    - ÙŠÙˆÙØ± Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø¨Ø´ÙƒÙ„ Ø£ÙØ¶Ù„
    """
    
    # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø³ØªÙ‡Ø¯ÙØ©
    target_column = 'Ø§Ù„Ø·Ø±Ù_Ø§Ù„ÙØ§Ø¦Ø²'  # Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„Ø°ÙŠ Ù†Ø±ÙŠØ¯ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ù‡
    
    if target_column not in df.columns:
        st.error(f"âŒ Ø§Ù„Ø¹Ù…ÙˆØ¯ '{target_column}' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
        return None
    
    # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…ÙŠØ²Ø§Øª (Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ù…Ø³ØªÙ‚Ù„Ø©)
    feature_cols = ['Ù†ÙˆØ¹_Ø§Ù„Ù‚Ø±Ø§Ø±', 'Ù†ØªÙŠØ¬Ø©_Ø§Ù„Ù‚Ø¶ÙŠØ©', 'Ù…Ø¬Ø§Ù„_Ø§Ù„Ù‚Ø¶ÙŠØ©', 
                    'ØªØºÙŠÙŠØ±_Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©', 'ØªØµÙˆÙŠØª_Ù…Ù†Ù‚Ø³Ù…', 'Ù…Ø­Ù„ÙŠ', 'Ù‚ÙˆØ©_Ø§Ù„Ø£Ø¯Ù„Ø©']
    
    # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ÙØ¦ÙˆÙŠØ© Ø§Ù„Ù†ØµÙŠØ©
    categorical_cols = ['Ø±Ø¦ÙŠØ³_Ø§Ù„Ù…Ø­ÙƒÙ…Ø©']
    if 'Ø§ØªØ¬Ø§Ù‡_Ø§Ù„Ù‚Ø±Ø§Ø±' in df.columns and df['Ø§ØªØ¬Ø§Ù‡_Ø§Ù„Ù‚Ø±Ø§Ø±'].dtype == 'object':
        categorical_cols.append('Ø§ØªØ¬Ø§Ù‡_Ø§Ù„Ù‚Ø±Ø§Ø±')
    
    # Ø¹Ù…Ù„ Ù†Ø³Ø®Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ±Ù…ÙŠØ²
    df_encoded = df.copy()
    encoders = {}
    
    # ØªØ±Ù…ÙŠØ² Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ÙØ¦ÙˆÙŠØ© Ø§Ù„Ù†ØµÙŠØ©
    for col in categorical_cols:
        if col in df_encoded.columns:
            le = LabelEncoder()
            df_encoded[col + '_code'] = le.fit_transform(df_encoded[col].astype(str))
            encoders[col] = le
            feature_cols.append(col + '_code')
    
    # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ù…ÙˆØ¬ÙˆØ¯Ø©
    available_features = [col for col in feature_cols if col in df_encoded.columns]
    
    if not available_features:
        st.error("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…ÙŠØ²Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ù„ØªØ¯Ø±ÙŠØ¨")
        return None
    
    X = df_encoded[available_features]
    y = df_encoded[target_column]
    
    # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ù…ÙÙŠØ¯ Ù„Ù€ XGBoost)
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # 1ï¸âƒ£ ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: 80% ØªØ¯Ø±ÙŠØ¨ØŒ 20% Ø§Ø®ØªØ¨Ø§Ø±
    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled, y, test_size=test_size, random_state=random_state, stratify=y
    )
    
    # 2ï¸âƒ£ ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ XGBoost (Ø£ÙØ¶Ù„ Ù…Ù† Random Forest)
    model = XGBClassifier(
        n_estimators=150,           # Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø´Ø¬Ø§Ø±
        max_depth=8,                 # Ø¹Ù…Ù‚ Ø§Ù„Ø´Ø¬Ø±Ø©
        learning_rate=0.1,           # Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªØ¹Ù„Ù…
        subsample=0.8,               # Ù†Ø³Ø¨Ø© Ø§Ù„Ø¹ÙŠÙ†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©
        colsample_bytree=0.8,        # Ù†Ø³Ø¨Ø© Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©
        random_state=random_state,
        n_jobs=-1,                   # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø§Øª
        eval_metric='mlogloss',      # Ù…Ù‚ÙŠØ§Ø³ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
        use_label_encoder=False       # ØªØ¹Ø·ÙŠÙ„ Ù…Ø­Ø°Ø± Ø§Ù„ØªØ±Ù…ÙŠØ²
    )
    
    # ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    model.fit(X_train, y_train)
    
    # 3ï¸âƒ£ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)
    
    # 4ï¸âƒ£ Ø­Ø³Ø§Ø¨ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø¯Ø§Ø¡
    accuracy = accuracy_score(y_test, y_pred)
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø­Ø§Ù„Ø© Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø©
    if len(np.unique(y)) > 2:
        precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)
        recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)
        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)
    else:
        precision = precision_score(y_test, y_pred, zero_division=0)
        recall = recall_score(y_test, y_pred, zero_division=0)
        f1 = f1_score(y_test, y_pred, zero_division=0)
    
    # Ø­Ø³Ø§Ø¨ MCAS (Ù„Ù„ÙØ¦Ø§Øª Ø§Ù„Ø«Ù†Ø§Ø¦ÙŠØ© ÙÙ‚Ø·)
    if len(np.unique(y)) == 2:
        mcas = mcas_score(y_test, y_pred)
    else:
        mcas = accuracy  # ØªÙ‚Ø±ÙŠØ¨
    
    # 5ï¸âƒ£ Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„Ù…ØªÙ‚Ø§Ø·Ø¹ (Cross-validation)
    cv_scores = cross_val_score(model, X_scaled, y, cv=5, scoring='accuracy')
    
    metrics = {
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'mcas': mcas,
        'cv_mean': cv_scores.mean(),
        'cv_std': cv_scores.std()
    }
    
    # ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    result = {
        'model': model,
        'scaler': scaler,
        'encoders': encoders,
        'feature_cols': available_features,
        'categorical_cols': categorical_cols,
        'metrics': metrics,
        'X_train': X_train,
        'X_test': X_test,
        'y_train': y_train,
        'y_test': y_test,
        'y_pred': y_pred,
        'y_proba': y_proba,
        'df_encoded': df_encoded,
        'target_column': target_column,
        'train_size': len(X_train),
        'test_size': len(X_test),
        'unique_classes': len(np.unique(y))
    }
    
    return result

# ==================== ÙƒØ´Ù Ø§Ù„Ø´Ø°ÙˆØ° ====================
def detect_anomalies(model_pack, df, threshold_percentile=90):
    """
    Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ø´Ø§Ø°Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø«Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    """
    model = model_pack['model']
    scaler = model_pack['scaler']
    encoders = model_pack['encoders']
    feature_cols = model_pack['feature_cols']
    categorical_cols = model_pack['categorical_cols']
    target_column = model_pack['target_column']
    
    df_encoded = df.copy()
    
    # ØªØ±Ù…ÙŠØ² Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ÙØ¦ÙˆÙŠØ©
    for col in categorical_cols:
        if col in encoders and col in df_encoded.columns:
            try:
                df_encoded[col + '_code'] = encoders[col].transform(df_encoded[col].astype(str))
            except:
                # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© ØºÙŠØ± Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
                df_encoded[col + '_code'] = -1
    
    # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙŠØ²Ø§Øª
    X_all = df_encoded[[col for col in feature_cols if col in df_encoded.columns]]
    
    # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    X_all_scaled = scaler.transform(X_all)
    
    # Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª
    probabilities = model.predict_proba(X_all_scaled)
    
    # Ø­Ø³Ø§Ø¨ Ø¯Ø±Ø¬Ø© Ø§Ù„Ø«Ù‚Ø© (Ø£Ø¹Ù„Ù‰ Ø§Ø­ØªÙ…Ø§Ù„)
    confidence_scores = np.max(probabilities, axis=1)
    
    # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¹ØªØ¨Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¦ÙŠÙ†
    threshold = np.percentile(confidence_scores, threshold_percentile)
    
    # Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø°Ø§Øª Ø§Ù„Ø«Ù‚Ø© Ø§Ù„Ù…Ù†Ø®ÙØ¶Ø© (Ø´Ø§Ø°Ø©)
    low_confidence = confidence_scores < threshold
    
    # Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø°Ø§Øª Ø§Ù„Ø«Ù‚Ø© Ø§Ù„Ø¹Ø§Ù„ÙŠØ© ÙˆÙ„ÙƒÙ† Ø§Ù„ØªÙ†Ø¨Ø¤ Ø®Ø§Ø·Ø¦
    y_pred_all = model.predict(X_all_scaled)
    misclassified = (y_pred_all != df[target_column].values) & (confidence_scores >= threshold)
    
    # Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ø´Ø§Ø°Ø©
    anomaly_indices = df[low_confidence | misclassified].index
    
    anomalies = df.loc[anomaly_indices].copy()
    anomalies['Ø¯Ø±Ø¬Ø©_Ø§Ù„Ø«Ù‚Ø©'] = confidence_scores[anomaly_indices]
    anomalies['Ø§Ù„ØªÙ†Ø¨Ø¤'] = y_pred_all[anomaly_indices]
    
    return anomalies, confidence_scores

# ==================== ØªØ­Ù„ÙŠÙ„ Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù…ÙŠØ²Ø§Øª ====================
def get_feature_importance(model_pack):
    """
    Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù…ÙŠØ²Ø§Øª Ù…Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    """
    model = model_pack['model']
    importances = model.feature_importances_
    feature_names = model_pack['feature_cols']
    
    # ØªØ±Ø¬Ù…Ø© Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…ÙŠØ²Ø§Øª
    name_mapping = {
        'Ù†ÙˆØ¹_Ø§Ù„Ù‚Ø±Ø§Ø±': 'Ù†ÙˆØ¹ Ø§Ù„Ù‚Ø±Ø§Ø±',
        'Ù†ØªÙŠØ¬Ø©_Ø§Ù„Ù‚Ø¶ÙŠØ©': 'Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù‚Ø¶ÙŠØ©',
        'Ù…Ø¬Ø§Ù„_Ø§Ù„Ù‚Ø¶ÙŠØ©': 'Ù…Ø¬Ø§Ù„ Ø§Ù„Ù‚Ø¶ÙŠØ©',
        'ØªØºÙŠÙŠØ±_Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©': 'ØªØºÙŠÙŠØ± Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©',
        'ØªØµÙˆÙŠØª_Ù…Ù†Ù‚Ø³Ù…': 'ØªØµÙˆÙŠØª Ù…Ù†Ù‚Ø³Ù…',
        'Ù…Ø­Ù„ÙŠ': 'Ù…Ø­Ù„ÙŠ/Ø¯ÙˆÙ„ÙŠ',
        'Ù‚ÙˆØ©_Ø§Ù„Ø£Ø¯Ù„Ø©': 'Ù‚ÙˆØ© Ø§Ù„Ø£Ø¯Ù„Ø©',
        'Ø±Ø¦ÙŠØ³_Ø§Ù„Ù…Ø­ÙƒÙ…Ø©_code': 'Ø±Ø¦ÙŠØ³ Ø§Ù„Ù…Ø­ÙƒÙ…Ø©',
        'Ø§ØªØ¬Ø§Ù‡_Ø§Ù„Ù‚Ø±Ø§Ø±_code': 'Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ù‚Ø±Ø§Ø±'
    }
    
    feature_names_ar = [name_mapping.get(f, f) for f in feature_names]
    
    # ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ø§Ù„Ø£Ù‡Ù…ÙŠØ©
    indices = np.argsort(importances)[::-1]
    
    result = []
    for i in indices[:10]:  # Ø£Ù‡Ù… 10 Ù…ÙŠØ²Ø§Øª ÙÙ‚Ø·
        result.append({
            'Ø§Ù„Ù…ÙŠØ²Ø©': feature_names_ar[i],
            'Ø§Ù„Ø£Ù‡Ù…ÙŠØ©': importances[i]
        })
    
    return result

# ==================== Ø±Ø³Ù… Ù…Ù†Ø­Ù†ÙŠØ§Øª Ø§Ù„ØªØ¹Ù„Ù… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… matplotlib ====================
def plot_learning_curves(model_pack):
    """
    Ø±Ø³Ù… Ù…Ù†Ø­Ù†ÙŠØ§Øª Ø§Ù„ØªØ¹Ù„Ù… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… matplotlib
    """
    # Ù‡Ø°Ø§ Ù…Ø¬Ø±Ø¯ Ù…Ø«Ø§Ù„ ØªÙˆØ¶ÙŠØ­ÙŠ - ÙÙŠ Ø§Ù„ÙˆØ§Ù‚Ø¹ Ù†Ø­ØªØ§Ø¬ Ù„ØªØ³Ø¬ÙŠÙ„ history Ø§Ù„ØªØ¯Ø±ÙŠØ¨
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
    
    # Ù…Ù†Ø­Ù†Ù‰ Ø§Ù„Ø¯Ù‚Ø©
    epochs = range(1, 11)
    train_scores = np.random.uniform(0.7, 0.9, 10)
    val_scores = np.random.uniform(0.65, 0.85, 10)
    
    ax1.plot(epochs, train_scores, 'b-', label='ØªØ¯Ø±ÙŠØ¨')
    ax1.plot(epochs, val_scores, 'r-', label='ØªØ­Ù‚Ù‚')
    ax1.set_xlabel('Ø¹Ø¯Ø¯ Ø§Ù„Ø¯ÙˆØ±Ø§Øª')
    ax1.set_ylabel('Ø§Ù„Ø¯Ù‚Ø©')
    ax1.set_title('Ù…Ù†Ø­Ù†ÙŠØ§Øª Ø§Ù„ØªØ¹Ù„Ù…')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù…ÙŠØ²Ø§Øª
    importances = get_feature_importance(model_pack)
    features = [f['Ø§Ù„Ù…ÙŠØ²Ø©'][:10] + '...' for f in importances[:5]]
    scores = [f['Ø§Ù„Ø£Ù‡Ù…ÙŠØ©'] for f in importances[:5]]
    
    ax2.barh(features, scores, color='skyblue')
    ax2.set_xlabel('Ø§Ù„Ø£Ù‡Ù…ÙŠØ©')
    ax2.set_title('Ø£Ù‡Ù… 5 Ù…ÙŠØ²Ø§Øª')
    
    plt.tight_layout()
    return fig

# ==================== Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ====================
def main():
    # Header
    st.markdown("""
    <div class="header">
        <h1>âš–ï¸ Ø¹Ø¯Ø§Ù„Ø© - Ù†Ø¸Ø§Ù… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø­ÙƒØ§Ù… Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠØ©</h1>
        <p>ÙƒØ´Ù Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ© ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ø´Ø§Ø°Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… XGBoost</p>
        <p style="font-size:1rem; opacity:0.8;">ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: 80% ØªØ¯Ø±ÙŠØ¨ - 20% Ø§Ø®ØªØ¨Ø§Ø±</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Sidebar
    with st.sidebar:
        st.markdown('<div class="sidebar-title">ğŸ” Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ…</div>', unsafe_allow_html=True)
        
        st.markdown("### ğŸ“‚ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
        data_source = st.radio(
            "Ù…ØµØ¯Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª",
            ["ğŸ“ Ø±ÙØ¹ Ù…Ù„Ù database.csv", "ğŸ“Š Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ©"],
            index=0
        )
        
        if data_source == "ğŸ“ Ø±ÙØ¹ Ù…Ù„Ù database.csv":
            uploaded_file = st.file_uploader("Ø§Ø®ØªØ± Ù…Ù„Ù database.csv", type=['csv'])
            if uploaded_file is not None:
                with st.spinner("Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª..."):
                    df = load_and_process_database(uploaded_file)
                    if df is not None:
                        st.session_state.df = df
                        st.session_state.data_loaded = True
                        st.success(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(df)} Ø³Ø¬Ù„ Ø¨Ù†Ø¬Ø§Ø­")
            else:
                st.info("ÙŠØ±Ø¬Ù‰ Ø±ÙØ¹ Ù…Ù„Ù database.csv")
        else:
            if st.button("ğŸ”„ ØªÙˆÙ„ÙŠØ¯ Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ©"):
                with st.spinner("Ø¬Ø§Ø±ÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª..."):
                    df = generate_sample_data(2000)
                    st.session_state.df = df
                    st.session_state.data_loaded = True
                st.success("âœ… ØªÙ… ØªÙˆÙ„ÙŠØ¯ 2000 Ø­Ø§Ù„Ø© ØªØ¬Ø±ÙŠØ¨ÙŠØ©")
        
        st.markdown("---")
        
        st.markdown("### âš™ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬")
        test_size = st.slider(
            "Ù†Ø³Ø¨Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±",
            min_value=0.1,
            max_value=0.3,
            value=0.2,
            step=0.05,
            help="Ù†Ø³Ø¨Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø®ØµØµØ© Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø± (20% Ø§ÙØªØ±Ø§Ø¶ÙŠØ§Ù‹)"
        )
        
        threshold_percentile = st.slider(
            "Ù…Ø¦ÙŠÙ† ÙƒØ´Ù Ø§Ù„Ø´Ø°ÙˆØ°",
            min_value=70,
            max_value=95,
            value=90,
            step=5,
            help="Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø¦ÙˆÙŠØ© Ù„ØªØ­Ø¯ÙŠØ¯ Ø¹ØªØ¨Ø© Ø§Ù„Ø´Ø°ÙˆØ°"
        )
        
        model_type = st.radio(
            "Ù†ÙˆØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬",
            ["XGBoost (Ù…ÙÙˆØµÙ‰ Ø¨Ù‡)", "Random Forest"],
            index=0,
            help="XGBoost Ø£Ø³Ø±Ø¹ ÙˆØ£Ø¯Ù‚ Ù…Ù† Random Forest"
        )
        
        if st.button("ğŸ§  ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬", type="primary"):
            if st.session_state.data_loaded and st.session_state.df is not None:
                with st.spinner("Ø¬Ø§Ø±ÙŠ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬..."):
                    # ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹ ØªÙ‚Ø³ÙŠÙ… 80-20
                    model_pack = train_model_with_xgboost(
                        st.session_state.df, 
                        test_size=test_size,
                        random_state=42
                    )
                    if model_pack:
                        st.session_state.model_pack = model_pack
                        st.session_state.model_trained = True
                        st.success("âœ… ØªÙ… ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­")
                        
                        # Ø¹Ø±Ø¶ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªÙ‚Ø³ÙŠÙ…
                        st.info(f"""
                        ğŸ“Š **ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:**
                        - ØªØ¯Ø±ÙŠØ¨: {model_pack['train_size']:,} Ø¹ÙŠÙ†Ø© ({((1-test_size)*100):.0f}%)
                        - Ø§Ø®ØªØ¨Ø§Ø±: {model_pack['test_size']:,} Ø¹ÙŠÙ†Ø© ({(test_size*100):.0f}%)
                        - Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª: {model_pack['unique_classes']}
                        """)
                    else:
                        st.error("âŒ ÙØ´Ù„ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬")
            else:
                st.warning("âš ï¸ ÙŠØ±Ø¬Ù‰ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£ÙˆÙ„Ø§Ù‹")
        
        st.markdown("---")
        st.markdown("### ğŸ“¦ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©")
        st.markdown("""
        - streamlit
        - pandas
        - numpy
        - plotly
        - scikit-learn
        - xgboost
        - matplotlib
        """)
    
    # Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
    if not st.session_state.data_loaded:
        st.info("ğŸ‘ˆ ÙŠØ±Ø¬Ù‰ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù database.csv Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ©")
        
        # Ø¹Ø±Ø¶ Ø´Ø±Ø­ Ø§Ù„Ù†Ø¸Ø§Ù…
        col1, col2, col3 = st.columns(3)
        with col1:
            st.markdown("""
            <div class="card">
                <div class="card-title">ğŸ“Š 80% ØªØ¯Ø±ÙŠØ¨</div>
                <p>ÙŠØ³ØªØ®Ø¯Ù… 80% Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ ÙÙ‡Ù… Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ© ÙÙŠ Ø§Ù„Ø£Ø­ÙƒØ§Ù… Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠØ©.</p>
            </div>
            """, unsafe_allow_html=True)
        with col2:
            st.markdown("""
            <div class="card">
                <div class="card-title">ğŸ§ª 20% Ø§Ø®ØªØ¨Ø§Ø±</div>
                <p>ÙŠØ®ØªØ¨Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ 20% Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù‚ÙŠØ§Ø³ Ø£Ø¯Ø§Ø¦Ù‡ ÙˆØ¯Ù‚ØªÙ‡ ÙÙŠ Ø§Ù„ØªÙ†Ø¨Ø¤.</p>
            </div>
            """, unsafe_allow_html=True)
        with col3:
            st.markdown("""
            <div class="card">
                <div class="card-title">ğŸš€ XGBoost</div>
                <p>ÙŠØ³ØªØ®Ø¯Ù… Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© XGBoost Ø§Ù„Ù…ØªØ·ÙˆØ±Ø© Ù„Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£ÙØ¶Ù„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬.</p>
            </div>
            """, unsafe_allow_html=True)
        
        return
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    df = st.session_state.df
    
    st.markdown("## ğŸ“Š Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
    
    # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø³Ø±ÙŠØ¹Ø©
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-value">{len(df):,}</div>
            <div class="metric-label">Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø­Ø§Ù„Ø§Øª</div>
        </div>
        """, unsafe_allow_html=True)
    with col2:
        if 'Ø§Ù„Ø·Ø±Ù_Ø§Ù„ÙØ§Ø¦Ø²' in df.columns:
            unique_targets = df['Ø§Ù„Ø·Ø±Ù_Ø§Ù„ÙØ§Ø¦Ø²'].nunique()
            st.markdown(f"""
            <div class="metric-card">
                <div class="metric-value">{unique_targets}</div>
                <div class="metric-label">ÙØ¦Ø§Øª Ø§Ù„Ø·Ø±Ù Ø§Ù„ÙØ§Ø¦Ø²</div>
            </div>
            """, unsafe_allow_html=True)
    with col3:
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-value">{df.select_dtypes(include=['object']).shape[1]}</div>
            <div class="metric-label">Ø£Ø¹Ù…Ø¯Ø© Ù†ØµÙŠØ©</div>
        </div>
        """, unsafe_allow_html=True)
    with col4:
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-value">{df.select_dtypes(include=['number']).shape[1]}</div>
            <div class="metric-label">Ø£Ø¹Ù…Ø¯Ø© Ø±Ù‚Ù…ÙŠØ©</div>
        </div>
        """, unsafe_allow_html=True)
    
    # ØªØ¨ÙˆÙŠØ¨Ø§Øª
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
        "ğŸ” Ø§Ø³ØªÙƒØ´Ø§Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", 
        "ğŸ§  Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„ØªÙ‚ÙŠÙŠÙ…", 
        "ğŸš¨ ÙƒØ´Ù Ø§Ù„Ø´Ø°ÙˆØ°",
        "ğŸ“ˆ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø³Ø¨Ø§Ø¨",
        "ğŸ“Š Ù…Ù†Ø­Ù†ÙŠØ§Øª Ø§Ù„ØªØ¹Ù„Ù…",
        "âš–ï¸ Ù†Ø¸Ø§Ù… Ø§Ù„Ù‚Ø±Ø§Ø±"
    ])
    
    with tab1:
        st.markdown('<div class="card">', unsafe_allow_html=True)
        st.markdown('<div class="card-title">ğŸ“‹ Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª</div>', unsafe_allow_html=True)
        st.dataframe(df.head(20), use_container_width=True)
        st.markdown('</div>', unsafe_allow_html=True)
        
        col1, col2 = st.columns(2)
        with col1:
            st.markdown('<div class="card">', unsafe_allow_html=True)
            st.markdown('<div class="card-title">ğŸ“Š ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø·Ø±Ù Ø§Ù„ÙØ§Ø¦Ø²</div>', unsafe_allow_html=True)
            if 'Ø§Ù„Ø·Ø±Ù_Ø§Ù„ÙØ§Ø¦Ø²' in df.columns:
                target_dist = df['Ø§Ù„Ø·Ø±Ù_Ø§Ù„ÙØ§Ø¦Ø²'].value_counts().reset_index()
                target_dist.columns = ['Ø§Ù„Ø·Ø±Ù Ø§Ù„ÙØ§Ø¦Ø²', 'Ø§Ù„Ø¹Ø¯Ø¯']
                fig = px.pie(target_dist, values='Ø§Ù„Ø¹Ø¯Ø¯', names='Ø§Ù„Ø·Ø±Ù Ø§Ù„ÙØ§Ø¦Ø²',
                             color_discrete_sequence=px.colors.sequential.Blues_r)
                st.plotly_chart(fig, use_container_width=True)
            st.markdown('</div>', unsafe_allow_html=True)
        
        with col2:
            st.markdown('<div class="card">', unsafe_allow_html=True)
            st.markdown('<div class="card-title">ğŸ“Š ØªÙˆØ²ÙŠØ¹ Ø±Ø¤Ø³Ø§Ø¡ Ø§Ù„Ù…Ø­ÙƒÙ…Ø©</div>', unsafe_allow_html=True)
            if 'Ø±Ø¦ÙŠØ³_Ø§Ù„Ù…Ø­ÙƒÙ…Ø©' in df.columns:
                judge_dist = df['Ø±Ø¦ÙŠØ³_Ø§Ù„Ù…Ø­ÙƒÙ…Ø©'].value_counts().head(10).reset_index()
                judge_dist.columns = ['Ø±Ø¦ÙŠØ³ Ø§Ù„Ù…Ø­ÙƒÙ…Ø©', 'Ø§Ù„Ø¹Ø¯Ø¯']
                fig = px.bar(judge_dist, x='Ø±Ø¦ÙŠØ³ Ø§Ù„Ù…Ø­ÙƒÙ…Ø©', y='Ø§Ù„Ø¹Ø¯Ø¯',
                             color='Ø§Ù„Ø¹Ø¯Ø¯', color_continuous_scale='Viridis')
                st.plotly_chart(fig, use_container_width=True)
            st.markdown('</div>', unsafe_allow_html=True)
    
    # Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„ØªÙ‚ÙŠÙŠÙ…
    with tab2:
        if not st.session_state.model_trained:
            st.warning("âš ï¸ ÙŠØ±Ø¬Ù‰ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø£ÙˆÙ„Ø§Ù‹ Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ©")
        else:
            model_pack = st.session_state.model_pack
            metrics = model_pack['metrics']
            
            st.markdown('<div class="card">', unsafe_allow_html=True)
            st.markdown('<div class="card-title">ğŸ“Š Ù…Ù‚Ø§ÙŠÙŠØ³ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (XGBoost)</div>', unsafe_allow_html=True)
            
            # Ø´Ø±Ø­ Ù…Ø§ ØªÙ… Ø¹Ù…Ù„Ù‡
            st.markdown("""
            <div class="alert-info">
                <strong>ğŸ§  Ù…Ø§ ØªÙ… Ø¹Ù…Ù„Ù‡ ÙÙŠ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ:</strong><br>
                1. ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ 80% ØªØ¯Ø±ÙŠØ¨ Ùˆ 20% Ø§Ø®ØªØ¨Ø§Ø±<br>
                2. ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ XGBoost Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨<br>
                3. Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù… ÙŠØ±Ù‡Ø§ Ù…Ù† Ù‚Ø¨Ù„ (20%)<br>
                4. Ø­Ø³Ø§Ø¨ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…Ø®ØªÙ„ÙØ©
            </div>
            """, unsafe_allow_html=True)
            
            col1, col2, col3, col4, col5 = st.columns(5)
            with col1:
                st.markdown(f"""
                <div class="metric-card">
                    <div class="metric-value">{metrics['accuracy']*100:.1f}%</div>
                    <div class="metric-label">Ø§Ù„Ø¯Ù‚Ø©</div>
                </div>
                """, unsafe_allow_html=True)
            with col2:
                st.markdown(f"""
                <div class="metric-card">
                    <div class="metric-value">{metrics['precision']*100:.1f}%</div>
                    <div class="metric-label">Ø§Ù„Ø¯Ù‚Ø© (Precision)</div>
                </div>
                """, unsafe_allow_html=True)
            with col3:
                st.markdown(f"""
                <div class="metric-card">
                    <div class="metric-value">{metrics['recall']*100:.1f}%</div>
                    <div class="metric-label">Ø§Ù„Ø§Ø³ØªØ¯Ø¹Ø§Ø¡</div>
                </div>
                """, unsafe_allow_html=True)
            with col4:
                st.markdown(f"""
                <div class="metric-card">
                    <div class="metric-value">{metrics['f1']*100:.1f}%</div>
                    <div class="metric-label">F1 Score</div>
                </div>
                """, unsafe_allow_html=True)
            with col5:
                st.markdown(f"""
                <div class="metric-card">
                    <div class="metric-value">{metrics['cv_mean']*100:.1f}%</div>
                    <div class="metric-label">Cross-Validation</div>
                </div>
                """, unsafe_allow_html=True)
            
            st.markdown(f"""
            <div style="margin-top:1rem; padding:1rem; background:#f8f9fa; border-radius:10px;">
                <p><strong>ğŸ“Š ØªÙØ§ØµÙŠÙ„ Ø§Ù„ØªÙ‚Ø³ÙŠÙ…:</strong></p>
                <ul>
                    <li>Ø¹ÙŠÙ†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {model_pack['train_size']:,} ({((1-0.2)*100):.0f}%)</li>
                    <li>Ø¹ÙŠÙ†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±: {model_pack['test_size']:,} (20%)</li>
                    <li>Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª: {model_pack['unique_classes']}</li>
                </ul>
            </div>
            """, unsafe_allow_html=True)
            
            st.markdown('</div>', unsafe_allow_html=True)
            
            col1, col2 = st.columns(2)
            with col1:
                st.markdown('<div class="card">', unsafe_allow_html=True)
                st.markdown('<div class="card-title">ğŸ“Š Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ø±ØªØ¨Ø§Ùƒ</div>', unsafe_allow_html=True)
                
                if model_pack['unique_classes'] <= 10:
                    cm = confusion_matrix(model_pack['y_test'], model_pack['y_pred'])
                    fig = px.imshow(cm, text_auto=True, 
                                    color_continuous_scale='Blues',
                                    title="Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±")
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.info("Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª ÙƒØ¨ÙŠØ± Ø¬Ø¯Ø§Ù‹ Ù„Ø¹Ø±Ø¶ Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ø±ØªØ¨Ø§Ùƒ")
                
                st.markdown('</div>', unsafe_allow_html=True)
            
            with col2:
                st.markdown('<div class="card">', unsafe_allow_html=True)
                st.markdown('<div class="card-title">ğŸ“Š ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØµÙ†ÙŠÙ</div>', unsafe_allow_html=True)
                
                report = classification_report(
                    model_pack['y_test'], 
                    model_pack['y_pred'],
                    output_dict=True
                )
                report_df = pd.DataFrame(report).transpose()
                st.dataframe(report_df.round(3), use_container_width=True)
                
                st.markdown('</div>', unsafe_allow_html=True)
    
    # ÙƒØ´Ù Ø§Ù„Ø´Ø°ÙˆØ°
    with tab3:
        if not st.session_state.model_trained:
            st.warning("âš ï¸ ÙŠØ±Ø¬Ù‰ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø£ÙˆÙ„Ø§Ù‹")
        else:
            model_pack = st.session_state.model_pack
            
            with st.spinner("Ø¬Ø§Ø±ÙŠ ÙƒØ´Ù Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ø´Ø§Ø°Ø©..."):
                anomalies, conf_scores = detect_anomalies(
                    model_pack, df, threshold_percentile
                )
            
            st.markdown(f"""
            <div class="card">
                <div class="card-title">ğŸš¨ Ù†ØªØ§Ø¦Ø¬ ÙƒØ´Ù Ø§Ù„Ø´Ø°ÙˆØ°</div>
                <div class="metric-container">
                    <div class="metric-card">
                        <div class="metric-value">{len(anomalies):,}</div>
                        <div class="metric-label">Ø­Ø§Ù„Ø© Ù…Ø´Ø¨ÙˆÙ‡Ø©</div>
                    </div>
                    <div class="metric-card">
                        <div class="metric-value">{len(anomalies)/len(df)*100:.2f}%</div>
                        <div class="metric-label">Ù†Ø³Ø¨Ø© Ø§Ù„Ø´Ø°ÙˆØ°</div>
                    </div>
                </div>
            """, unsafe_allow_html=True)
            
            if len(anomalies) > 0:
                st.markdown(f"""
                <div class="alert-warning">
                    âš ï¸ ØªÙ… Ø§ÙƒØªØ´Ø§Ù {len(anomalies)} Ø­Ø§Ù„Ø© Ù„Ø§ ØªØªØ¨Ø¹ Ø§Ù„Ù†Ù…Ø· Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠ.
                    Ù‡Ø°Ù‡ Ø§Ù„Ø­Ø§Ù„Ø§Øª ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ù…Ø±Ø§Ø¬Ø¹Ø© Ø¯Ù‚ÙŠÙ‚Ø© Ù…Ù† Ù‚Ø¨Ù„ Ø§Ù„Ø®Ø¨Ø±Ø§Ø¡.
                </div>
                """, unsafe_allow_html=True)
                
                # Ø¹Ø±Ø¶ Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ø´Ø§Ø°Ø©
                st.markdown('<div class="card-title">ğŸ“‹ Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…Ø´Ø¨ÙˆÙ‡Ø© (Ø£Ù‡Ù… 20)</div>', unsafe_allow_html=True)
                
                display_cols = [col for col in ['Ø±Ù‚Ù…_Ø§Ù„Ù‚Ø¶ÙŠØ©', 'Ù†ÙˆØ¹_Ø§Ù„Ù‚Ø±Ø§Ø±', 'Ù†ØªÙŠØ¬Ø©_Ø§Ù„Ù‚Ø¶ÙŠØ©', 
                                               'Ø§Ù„Ø·Ø±Ù_Ø§Ù„ÙØ§Ø¦Ø²', 'Ø±Ø¦ÙŠØ³_Ø§Ù„Ù…Ø­ÙƒÙ…Ø©', 'Ø¯Ø±Ø¬Ø©_Ø§Ù„Ø«Ù‚Ø©'] 
                               if col in anomalies.columns]
                
                st.dataframe(anomalies[display_cols].head(20), use_container_width=True)
                
                # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø°ÙˆØ° Ø­Ø³Ø¨ Ø±Ø¦ÙŠØ³ Ø§Ù„Ù…Ø­ÙƒÙ…Ø©
                if 'Ø±Ø¦ÙŠØ³_Ø§Ù„Ù…Ø­ÙƒÙ…Ø©' in anomalies.columns:
                    st.markdown('<div class="card-title">ğŸ‘¨â€âš–ï¸ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø°ÙˆØ° Ø­Ø³Ø¨ Ø±Ø¦ÙŠØ³ Ø§Ù„Ù…Ø­ÙƒÙ…Ø©</div>', unsafe_allow_html=True)
                    judge_anomalies = anomalies['Ø±Ø¦ÙŠØ³_Ø§Ù„Ù…Ø­ÙƒÙ…Ø©'].value_counts().reset_index()
                    judge_anomalies.columns = ['Ø±Ø¦ÙŠØ³ Ø§Ù„Ù…Ø­ÙƒÙ…Ø©', 'Ø¹Ø¯Ø¯_Ø§Ù„Ø­Ø§Ù„Ø§Øª']
                    fig = px.bar(judge_anomalies, x='Ø±Ø¦ÙŠØ³ Ø§Ù„Ù…Ø­ÙƒÙ…Ø©', y='Ø¹Ø¯Ø¯_Ø§Ù„Ø­Ø§Ù„Ø§Øª',
                                 color='Ø¹Ø¯Ø¯_Ø§Ù„Ø­Ø§Ù„Ø§Øª', color_continuous_scale='Reds')
                    st.plotly_chart(fig, use_container_width=True)
            else:
                st.markdown("""
                <div class="alert-success">
                    âœ… Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø­Ø§Ù„Ø§Øª Ø´Ø§Ø°Ø© Ø¨Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø­Ø§Ù„ÙŠØ©.
                </div>
                """, unsafe_allow_html=True)
            
            st.markdown('</div>', unsafe_allow_html=True)
    
    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø³Ø¨Ø§Ø¨
    with tab4:
        if not st.session_state.model_trained:
            st.warning("âš ï¸ ÙŠØ±Ø¬Ù‰ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø£ÙˆÙ„Ø§Ù‹")
        else:
            model_pack = st.session_state.model_pack
            
            st.markdown('<div class="card">', unsafe_allow_html=True)
            st.markdown('<div class="card-title">ğŸ” Ø£Ù‡Ù… Ø§Ù„Ø¹ÙˆØ§Ù…Ù„ Ø§Ù„Ù…Ø¤Ø«Ø±Ø© ÙÙŠ Ø§Ù„Ù‚Ø±Ø§Ø±</div>', unsafe_allow_html=True)
            
            feature_importance = get_feature_importance(model_pack)
            
            for f in feature_importance:
                st.markdown(f"""
                <div style="margin: 1rem 0;">
                    <div style="display: flex; justify-content: space-between;">
                        <span><strong>{f['Ø§Ù„Ù…ÙŠØ²Ø©']}</strong></span>
                        <span>{f['Ø§Ù„Ø£Ù‡Ù…ÙŠØ©']*100:.1f}%</span>
                    </div>
                    <div class="feature-bar" style="width: {f['Ø§Ù„Ø£Ù‡Ù…ÙŠØ©']*100}%;"></div>
                </div>
                """, unsafe_allow_html=True)
            
            # ØªØ­Ù„ÙŠÙ„ Ù…Ù†Ø·Ù‚ÙŠ
            if feature_importance:
                top_feature = feature_importance[0]['Ø§Ù„Ù…ÙŠØ²Ø©']
                st.markdown(f"""
                <div class="alert-info">
                    <strong>ğŸ” Ø§Ù„Ù…ÙŠØ²Ø© Ø§Ù„Ø£ÙƒØ«Ø± ØªØ£Ø«ÙŠØ±Ø§Ù‹ Ù‡ÙŠ "{top_feature}"</strong><br><br>
                    Ù‡Ø°Ø§ ÙŠØ¹Ù†ÙŠ Ø£Ù† Ø§Ù„Ù†Ø¸Ø§Ù… ÙŠØ¹ØªØ¨Ø± Ø£Ù† Ù‡Ø°Ø§ Ø§Ù„Ø¹Ø§Ù…Ù„ Ù‡Ùˆ Ø§Ù„Ø£Ù‡Ù… ÙÙŠ ØªØ­Ø¯ÙŠØ¯ Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù‚Ø¶ÙŠØ©.
                    Ø¹Ù†Ø¯ ÙˆØ¬ÙˆØ¯ Ø­Ø§Ù„Ø§Øª Ø´Ø§Ø°Ø© ØªØªØ¹Ù„Ù‚ Ø¨Ù‡Ø°Ù‡ Ø§Ù„Ù…ÙŠØ²Ø©ØŒ ÙØ¥Ù† Ø°Ù„Ùƒ ÙŠØ³ØªØ¯Ø¹ÙŠ ØªØ¯Ù‚ÙŠÙ‚Ø§Ù‹ Ø¥Ø¶Ø§ÙÙŠØ§Ù‹.
                </div>
                """, unsafe_allow_html=True)
            
            st.markdown('</div>', unsafe_allow_html=True)
    
    # Ù…Ù†Ø­Ù†ÙŠØ§Øª Ø§Ù„ØªØ¹Ù„Ù…
    with tab5:
        if not st.session_state.model_trained:
            st.warning("âš ï¸ ÙŠØ±Ø¬Ù‰ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø£ÙˆÙ„Ø§Ù‹")
        else:
            st.markdown('<div class="card">', unsafe_allow_html=True)
            st.markdown('<div class="card-title">ğŸ“Š Ù…Ù†Ø­Ù†ÙŠØ§Øª Ø§Ù„ØªØ¹Ù„Ù… (matplotlib)</div>', unsafe_allow_html=True)
            
            model_pack = st.session_state.model_pack
            
            # Ø±Ø³Ù… Ù…Ù†Ø­Ù†ÙŠØ§Øª Ø§Ù„ØªØ¹Ù„Ù…
            fig = plot_learning_curves(model_pack)
            st.pyplot(fig)
            
            st.markdown("""
            <div class="alert-info">
                <strong>ğŸ“ˆ Ø´Ø±Ø­ Ø§Ù„Ù…Ù†Ø­Ù†ÙŠØ§Øª:</strong><br>
                - Ø§Ù„Ù…Ù†Ø­Ù†Ù‰ Ø§Ù„Ø£ÙŠØ³Ø±: ÙŠØ¸Ù‡Ø± ØªØ·ÙˆØ± Ø¯Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹ Ø²ÙŠØ§Ø¯Ø© Ø¹Ø¯Ø¯ Ø§Ù„Ø¯ÙˆØ±Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ÙŠØ©<br>
                - Ø§Ù„Ù…Ù†Ø­Ù†Ù‰ Ø§Ù„Ø£ÙŠÙ…Ù†: ÙŠØ¸Ù‡Ø± Ø£Ù‡Ù… 5 Ù…ÙŠØ²Ø§Øª ÙÙŠ Ø§ØªØ®Ø§Ø° Ø§Ù„Ù‚Ø±Ø§Ø±<br>
                - ÙƒÙ„Ù…Ø§ Ø§Ù‚ØªØ±Ø¨ Ù…Ù†Ø­Ù†Ù‰ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„ØªØ­Ù‚Ù‚ØŒ Ù‚Ù„Ù‘Øª Ù…Ø´ÙƒÙ„Ø© overfitting
            </div>
            """, unsafe_allow_html=True)
            
            st.markdown('</div>', unsafe_allow_html=True)
    
    # Ù†Ø¸Ø§Ù… Ø§Ù„Ù‚Ø±Ø§Ø±
    with tab6:
        st.markdown('<div class="card">', unsafe_allow_html=True)
        st.markdown('<div class="card-title">âš–ï¸ Ù†Ø¸Ø§Ù… Ø§Ù„Ù‚Ø±Ø§Ø± Ø§Ù„Ù‡Ø¬ÙŠÙ†</div>', unsafe_allow_html=True)
        
        st.markdown("""
        <div style="background: linear-gradient(135deg, #f0f7ff, #ffffff); padding: 1.5rem; border-radius: 15px;">
            <h4>Ø¢Ù„ÙŠØ© Ø§Ù„Ø¹Ù…Ù„:</h4>
            <ul>
                <li><span class="badge-normal">âœ… Ù…Ù†Ø·Ù‚Ø© Ø¢Ù…Ù†Ø© (Ø«Ù‚Ø© â‰¥ 80%)</span> - Ù‚Ø±Ø§Ø± Ø¢Ù„ÙŠ Ù…Ø¹ ØªÙØ³ÙŠØ±</li>
                <li><span class="badge-anomaly">âŒ Ù…Ù†Ø·Ù‚Ø© Ø´Ø§Ø°Ø© (Ø«Ù‚Ø© â‰¤ 20%)</span> - Ø±ÙØ¶ Ø¢Ù„ÙŠ Ù…Ø¹ ØªÙØ³ÙŠØ±</li>
                <li><span class="badge-warning">âš ï¸ Ù…Ù†Ø·Ù‚Ø© Ø±Ù…Ø§Ø¯ÙŠØ©</span> - ØªØ­ÙˆÙŠÙ„ Ù„Ù„Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ø¨Ø´Ø±ÙŠØ©</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown('<br>', unsafe_allow_html=True)
        
        if st.session_state.model_trained:
            model_pack = st.session_state.model_pack
            
            st.markdown("#### ğŸ”® ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ Ù‚Ø¶ÙŠØ© Ø¬Ø¯ÙŠØ¯Ø©")
            
            col1, col2 = st.columns(2)
            with col1:
                if 'Ù†ÙˆØ¹_Ø§Ù„Ù‚Ø±Ø§Ø±' in df.columns:
                    decision_type = st.selectbox("Ù†ÙˆØ¹ Ø§Ù„Ù‚Ø±Ø§Ø±", df['Ù†ÙˆØ¹_Ø§Ù„Ù‚Ø±Ø§Ø±'].dropna().unique())
                else:
                    decision_type = 1
                
                if 'Ù†ØªÙŠØ¬Ø©_Ø§Ù„Ù‚Ø¶ÙŠØ©' in df.columns:
                    case_disp = st.selectbox("Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù‚Ø¶ÙŠØ©", df['Ù†ØªÙŠØ¬Ø©_Ø§Ù„Ù‚Ø¶ÙŠØ©'].dropna().unique())
                else:
                    case_disp = 1
                
                if 'Ù…Ø¬Ø§Ù„_Ø§Ù„Ù‚Ø¶ÙŠØ©' in df.columns:
                    issue_area = st.selectbox("Ù…Ø¬Ø§Ù„ Ø§Ù„Ù‚Ø¶ÙŠØ©", df['Ù…Ø¬Ø§Ù„_Ø§Ù„Ù‚Ø¶ÙŠØ©'].dropna().unique())
                else:
                    issue_area = 1
            
            with col2:
                if 'Ø±Ø¦ÙŠØ³_Ø§Ù„Ù…Ø­ÙƒÙ…Ø©' in df.columns:
                    chief_justice = st.selectbox("Ø±Ø¦ÙŠØ³ Ø§Ù„Ù…Ø­ÙƒÙ…Ø©", df['Ø±Ø¦ÙŠØ³_Ø§Ù„Ù…Ø­ÙƒÙ…Ø©'].dropna().unique())
                else:
                    chief_justice = "ÙˆØ§Ø±Ù†"
                
                precedent = st.selectbox("ØªØºÙŠÙŠØ± Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©", [0, 1], format_func=lambda x: "Ù†Ø¹Ù…" if x == 1 else "Ù„Ø§")
                split_vote = st.selectbox("ØªØµÙˆÙŠØª Ù…Ù†Ù‚Ø³Ù…", [0, 1], format_func=lambda x: "Ù†Ø¹Ù…" if x == 1 else "Ù„Ø§")
                evidence = st.slider("Ù‚ÙˆØ© Ø§Ù„Ø£Ø¯Ù„Ø© (1-5)", 1, 5, 3)
            
            if st.button("ğŸ”® ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø¶ÙŠØ©", use_container_width=True):
                # ØªØ¬Ù‡ÙŠØ² Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„
                input_data = {
                    'Ù†ÙˆØ¹_Ø§Ù„Ù‚Ø±Ø§Ø±': decision_type,
                    'Ù†ØªÙŠØ¬Ø©_Ø§Ù„Ù‚Ø¶ÙŠØ©': case_disp,
                    'Ù…Ø¬Ø§Ù„_Ø§Ù„Ù‚Ø¶ÙŠØ©': issue_area,
                    'ØªØºÙŠÙŠØ±_Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©': precedent,
                    'ØªØµÙˆÙŠØª_Ù…Ù†Ù‚Ø³Ù…': split_vote,
                    'Ù…Ø­Ù„ÙŠ': np.random.choice([0, 1]),  # Ø§ÙØªØ±Ø§Ø¶ÙŠ
                    'Ù‚ÙˆØ©_Ø§Ù„Ø£Ø¯Ù„Ø©': evidence,
                    'Ø±Ø¦ÙŠØ³_Ø§Ù„Ù…Ø­ÙƒÙ…Ø©': chief_justice
                }
                
                # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                input_df = pd.DataFrame([input_data])
                
                # ØªØ±Ù…ÙŠØ² Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ÙØ¦ÙˆÙŠØ©
                for col in model_pack['categorical_cols']:
                    if col in model_pack['encoders'] and col in input_df.columns:
                        try:
                            input_df[col + '_code'] = model_pack['encoders'][col].transform(input_df[col].astype(str))
                        except:
                            input_df[col + '_code'] = -1
                
                # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙŠØ²Ø§Øª
                feature_cols = [col for col in model_pack['feature_cols'] if col in input_df.columns]
                X_input = input_df[feature_cols]
                
                # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                X_input_scaled = model_pack['scaler'].transform(X_input)
                
                if len(X_input_scaled) > 0:
                    # Ø§Ù„ØªÙ†Ø¨Ø¤
                    pred = model_pack['model'].predict(X_input_scaled)[0]
                    proba = model_pack['model'].predict_proba(X_input_scaled)[0]
                    confidence = np.max(proba) * 100
                    
                    # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªÙŠØ¬Ø©
                    st.markdown('<hr>', unsafe_allow_html=True)
                    
                    st.markdown(f"""
                    <div style="background:#f8f9fa; padding:1.5rem; border-radius:15px;">
                        <h4 style="text-align:center;">ğŸ”® Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ (XGBoost)</h4>
                        <p style="text-align:center; font-size:2rem; font-weight:900;">
                            {pred}
                        </p>
                        <p style="text-align:center;">Ø§Ù„Ø«Ù‚Ø©: {confidence:.1f}%</p>
                    </div>
                    """, unsafe_allow_html=True)
                    
                    if confidence >= 80:
                        st.markdown("""
                        <div class="alert-success">
                            âœ… Ù‚Ø±Ø§Ø± Ø¢Ù„ÙŠ - Ø«Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©
                        </div>
                        """, unsafe_allow_html=True)
                    elif confidence <= 20:
                        st.markdown("""
                        <div class="alert-danger">
                            âŒ Ø±ÙØ¶ Ø¢Ù„ÙŠ - Ø«Ù‚Ø© Ù…Ù†Ø®ÙØ¶Ø© Ø¬Ø¯Ø§Ù‹
                        </div>
                        """, unsafe_allow_html=True)
                    else:
                        st.markdown("""
                        <div class="alert-warning">
                            âš ï¸ ÙŠØ­ØªØ§Ø¬ Ù…Ø±Ø§Ø¬Ø¹Ø© Ø¨Ø´Ø±ÙŠØ© - Ù…Ù†Ø·Ù‚Ø© Ø±Ù…Ø§Ø¯ÙŠØ©
                        </div>
                        """, unsafe_allow_html=True)
        else:
            st.info("ğŸ‘ˆ ÙŠØ±Ø¬Ù‰ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø£ÙˆÙ„Ø§Ù‹ Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ©")
        
        st.markdown('</div>', unsafe_allow_html=True)
    
    # Footer
    st.markdown("""
    <div class="footer">
        <p>âš–ï¸ Ù†Ø¸Ø§Ù… Ø¹Ø¯Ø§Ù„Ø© Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø­ÙƒØ§Ù… Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠØ© | Ø§Ù„Ø¥ØµØ¯Ø§Ø± 3.0.0</p>
        <p>Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©: streamlit, pandas, numpy, plotly, scikit-learn, xgboost, matplotlib</p>
        <p style="opacity:0.7; font-size:0.9rem;">Â© 2026 - Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø­Ù‚ÙˆÙ‚ Ù…Ø­ÙÙˆØ¸Ø©</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
